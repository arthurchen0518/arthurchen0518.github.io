<!--  -->
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name="google-site-verification" content="3l9iSXOYZI5WUxYehDjXug3JAWy4ebqEpCvd3iuALWE" />
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="seal_icon.png">
  <title>Kefan (Arthur) Chen</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="67%" valign="middle">
          <p align="center">
            <name>Kefan (Arthur) Chen</name>
          </p>
            <p align="center">kefan_chen@brown.edu</p>
          <p>
            I'm a 3rd year Ph.D. candidate at Brown University, advised by <a href="https://cs.brown.edu/people/ssrinath/"> Prof. Srinath Sridhar</a>. 
            My research focuses on developing intelligent agents that understand and learn dexterous skills from humans, with the goal of enabling robotic assistance for everyday tasks.
            My expertise encompasses 3D vision, Generative AI, Language Vision Models (LVMs), digital humans, neural rendering, and Large Multimodal Models (LMMs). 
            <br><br>
            Previously, I obtained my bachelor’s degree in ECE from the University of Toronto in 2018. Then, I worked as a research scientist and ML engineer at Google Research, Pinterest, and autonomous driving startups from 2018 to 2022. I had the honor to work with <a href="http://www.ameeshmakadia.com/index.html"> Dr. Ameesh Makadia </a> and 
            <a href="https://www.cs.cornell.edu/~snavely/"> Prof. Noah Snavely</a> at Google Research, and <a href="https://www.cs.toronto.edu/~urtasun/"> Prof. Raquel Urtasun</a> 
            and <a href="https://www.cs.utoronto.ca/~fidler/index.html"> Prof. Sanja Fidler</a> at UofT. 
            Along my academic journey, I also interned at NVIDIA, Meta, and Waymo. 
          </p>
          
          </td>
                                                                                                             
          <td width="33%">
            <img src="assets/portrait.jpg" width="200">
          </td>



        </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <p align=center>
          <img style="width: 18px; height:18px;" src="assets/resume_logo.png">
          <a href="assets/CurriculumVitae.pdf">CV</a> &nbsp / &nbsp
          <img style="width: 18px; height:18px;" src="assets/linkedIn_logo.png">
          <a href="https://www.linkedin.com/in/kefanc"> LinkedIn </a> &nbsp / &nbsp
          <img style="width: 18px; height:18px;" src="assets/google_scholar.jpg">
          <a href="https://scholar.google.com/citations?user=A6FPlHcAAAAJ&hl=en">Google Scholar</a>
        </p>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading>Publications</heading>
          </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        
        <tr bgcolor="#ffffff">
          <td width="25%">
            <img src="assets/interact_avatar.png" width='250'></div>   
          </td>
          <td valign="top" width="75%">
            <p>
              <papertitle>InteractAvatar: Modeling Hand-Face Interaction in Photorealistic Avatars with Deformable Gaussians</papertitle>
              <br><strong>Kefan Chen</strong>, Sreyas Mohan*, Justin Theiss*, Sergiu Oprea*, Srinath Sridhar, Aayush Prakash<br>
              <em>International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2025. <br>
               [<a href='https://arxiv.org/abs/2504.07949'>Paper</a>]
               [<a href='https://arthurchen0518.github.io/InteractAvatar'>Website</a>] 
             
              <br>
            </p>
          </td>
        </tr>
        
        <tr bgcolor="#ffffff">
          <td width="25%">
            <img src="assets/foundhand.png" width='250'></div>   
          </td>
          <td valign="top" width="75%">
            <p>
              <papertitle>FoundHand: Large-Scale Domain-Specific Learning for Controllable Hand Image Generation</papertitle>
              <br><strong>Kefan Chen</strong>*, Chaerin Min*, Linguang Zhang, Shreyas Hampali, Cem Keskin, Srinath Sridhar<br>
              <em>Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2025. (<span style="color: red;"><strong>Highlight, 2.98% acceptance rate.</strong></span>) <br> 
              [<a href='https://arxiv.org/pdf/2412.02690'>Paper</a>]
<!--               [<a href='https://youtu.be/26tBmSOXxHo'>Video</a>] -->
              [<a href='https://ivl.cs.brown.edu/research/foundhand.html'>Website</a>]
             
              <br>
            </p>
          </td>
        </tr>
        
        <tr bgcolor="#ffffff">
          <td width="25%">
            <img src="assets/uvgs.jpg" width='250'></div>   
          </td>
          <td valign="top" width="75%">
            <p>
              <papertitle>UVGS: Reimagining Unstructured 3D Gaussian Splatting using UV Mapping</papertitle>
              <br>Aashish Rai, Dilin Wang, Mihir Jain, Nikolaos Sarafianos, <strong>Kefan Chen</strong>, Srinath Sridhar, Aayush Prakash<br>
              <em>Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2025. <br> 
              [<a href='https://www.arxiv.org/pdf/2502.01846'>Paper</a>]
              [<a href='https://youtu.be/Z-VcmzXbfzg'>Video</a>]
              [<a href='https://aashishrai3799.github.io/uvgs/'>Website</a>]
             
              <br>
            </p>
          </td>
        </tr>

        
        <tr bgcolor="#ffffff">
          <td width="25%">
            <img src="assets/MANUS.png" width='250'></div>   
          </td>
          <td valign="top" width="75%">
            <p>
              <papertitle>MANUS: Markerless Hand-Object Grasp Capture using Articulated 3D Gaussians</papertitle>
              <br>Chandradeep Pokhariya, Ishaan Shah, Angela Xing, Zekun Li, <strong>Kefan Chen</strong>, Avinash Sharma, Srinath Sridhar<br>
              <em>Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2024. <br>
              [<a href='https://arxiv.org/pdf/2312.02137.pdf'>Paper</a>]
              [<a href='https://ivl.cs.brown.edu/research/manus.html'>Website</a>]
              [<a href='https://github.com/brown-ivl/manus'>Code</a>]
              [<a href='https://github.com/brown-ivl/manus#manus-grasps-dataset'>Dataset</a>]
             
              <br>
            </p>
          </td>
        </tr>
        
        <tr bgcolor="#ffffff">
          <td width="25%">
            <img src="assets/diva360.png" width='250'></div>   
          </td>
          <td valign="top" width="75%">
            <p>
              <papertitle>DiVa-360: The Dynamic Visual Dataset for Immersive Neural Fields</papertitle>
              <br>Cheng-You Lu, Peisen Zhou, Angela Xing, Chandradeep Pokhariya, Arnab Dey, Ishaan Shah, Rugved Mavidipalli, Dylan Hu, Andrew Comport, <strong>Kefan Chen</strong>, Srinath Sridhar<br>
              <em>Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2024. (<span style="color: red;"><strong>Highlight, 2.81% acceptance rate.</strong></span>) <br>
              [<a href='https://arxiv.org/pdf/2307.16897.pdf'>Paper</a>]
              [<a href='https://youtu.be/26tBmSOXxHo'>Video</a>]
              [<a href='https://diva360.github.io/'>Website</a>]
              [<a href='https://github.com/brown-ivl/DiVa360'>Code</a>]
              [<a href='https://ivl.cs.brown.edu/research/diva#downloading-data'>Dataset</a>]
             
              
              
              
              <br>
            </p>
          </td>
        </tr>

        
        <tr bgcolor="#ffffff">
          <td width="25%">
            <img src="assets/TrainingPipeline_fill.png" width='250'></div>   
          </td>
          <td valign="top" width="75%">
            <p>
              <papertitle>Wide-Baseline Relative Camera Pose Estimation with Directional Learning</papertitle>
              <br>
              <strong>Kefan Chen</strong>, Noah, Snavely, Ameesh Makadia<br>
              <em>Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2021. <br>
              [<a href='https://arxiv.org/pdf/2106.03336.pdf'>Paper</a>]
              [<a id='directionnet_bib' onclick='detail_switch(this.id)'>Bibtex</a>]
              [<a href='https://www.youtube.com/watch?v=tJ2JTFmi0oI'>Video</a>]
              [<a href='https://arthurchen0518.github.io/DirectionNet'>Website</a>]
              [<a href='https://github.com/arthurchen0518/DirectionNet'>Code</a>]
              
              
              
              <br>
            </p>
            
            <p>
              <div id='directionnet_bib_content' style="font-family:monospace;display:none;">
@InProceedings{Chen_2021_CVPR,
    author    = {Chen, Kefan and Snavely, Noah and Makadia, Ameesh},
    title     = {Wide-Baseline Relative Camera Pose Estimation With Directional Learning},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {3258-3268}
}
                
              </div>
            </p>
            <p></p>
          </td>
        </tr>
  
        <tr bgcolor="#ffffff">
          <td width="25%"> 
            <img src="assets/svd_analysis.png" width='250'></div>  
          </td>
          <td valign="top" width="75%">
            <p>
              <papertitle>An Analysis of SVD for Deep Rotation Estimation</papertitle>
              <br>
              Jake Levinson, Carlos Esteves, <strong>Kefan Chen</strong>, Noah Snavely, Angjoo Kanazawa, Afshin Rostamizadeh, Ameesh Makadia<br>
              <em>Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2020. <br>
              [<a href='https://arxiv.org/pdf/2006.14616.pdf'>Paper</a>]  
              [<a id='svd_bib' onclick='detail_switch(this.id)'>Bibtex</a>]  
              [<a href='https://www.youtube.com/watch?v=_lvz3KdZr_I'>Video</a>]
              [<a href='https://github.com/google-research/google-research/tree/master/special_orthogonalization'>Code</a>]
              
              <br>
            </p>

            <p>
              <div id='svd_bib_content' style="font-family:monospace;display:none;">
                @inproceedings{levinson20neurips,
                  title = {An Analysis of {SVD} for Deep Rotation Estimation},
                  author = {Jake Levinson, Carlos Esteves, Kefan Chen, Noah Snavely, Angjoo Kanazawa, Afshin Rostamizadeh, and Ameesh Makadia},
                  booktitle = {Advances in Neural Information Processing Systems 34},
                  year = {2020}
                }
              </div>
            </p>
            <p></p>

          </td>
        </tr>

      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td>
          <heading>Education</heading>
          </td>
        </tr>
        
      </table>
      
      <table width="100%" align="center" border="0" cellpadding="20">
        <tr>
          <td width="25%"><img src="assets/brown.png" alt="prl" width="160" ></td>
          <td width="75%" valign="top">
            <p>
              <big> Brown University </big> <br> 
              Ph.D. student in Computer Science <br>
              Research Areas:	3D Vision, GenAI, Digital Human, LVM, Embodied AI, VR/XR. <br>
              2022 - 2027 <br>
            </p>
          </td>
        </tr>
        
        <tr>
          <td width="25%"><img src="assets/UofT-Logo.png" alt="prl" width="160" ></td>
          <td width="75%" valign="top">
            <p>
              <big> University of Toronto </big> <br> 
              B.Eng. in Electrical Engineering <br>
              2014 - 2018 <br>
            </p>
          </td>
        </tr>
        
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td>
          <heading>Industry</heading>
          </td>
        </tr>
        
      </table>
       
        
      <table width="100%" align="center" border="0" cellpadding="20">
        
        <tr>
          <td width="25%"><img src="assets/Waymo_logo.png" alt="prl" width="145" ></td>
          <td width="75%" valign="top">
            <p>
              <big>Waymo </big> <br> 
              Research Intern<br>
              Mountainview, CA <br>
              June, 2025 -  Current<br>
            </p>
            <p></p>
            <p>
              Research perception on L4 autonomous driving.
            </p>
          </td>
        </tr>
        
        <tr>
          <td width="25%"><img src="assets/meta-logo.png" alt="prl" width="160" ></td>
          <td width="75%" valign="top">
            <p>
              <big>Meta</big> <br> 
              Research Scientist Intern<br>
              Burlingame, CA <br>
              June, 2024 - Mar, 2025  <br>
            </p>
            <p></p>
            <p>
              Research large image and video diffusion model for dexterous hand generation.
            </p>
            <p>
              Seattle, WA <br>
              June, 2023 - Dec, 2023 <br>
            </p>
            <p>
              Research interactive 3D human avatars using Gaussian Splatting for realistic digital human and VR/XR.
            </p>
            
          </td>
        </tr>

        <tr>
          <td width="25%"><img src="assets/Pinterest-Logo.png" alt="prl" width="160" ></td>
          <td width="75%" valign="top">
            <p>
              <big> Pinterest </big> <br> 
              Machine Learning Engineer<br>
              Toronto, Canada <br>
              January, 2022 -  September, 2022<br>
            </p>
            <p></p>
            <p>
              ML for shopping content mining.
            </p>
          </td>
        </tr>
        
        <tr>
          <td width="25%"><img src="assets/gatik_logo.png" alt="prl" width="160" ></td>
          <td width="75%" valign="top">
            <p>
              <big> Gatik </big> <br> 
              Toronto, Canada <br>
              September, 2020 - December, 2021 <br>
            </p>
            <p></p>
            <p>
              Develop long-range multimodal perception for self-driving trucks.
            </p>
          </td>
        </tr>
        
        <tr>
          <td width="25%"><img src="assets/google_research_logo.jpg" alt="prl" width="180" ></td>
          <td width="75%" valign="top">
            <p>
              <big>Google Research </big> <br> 
              AI Resident<br>
              New York City, NY <br>
              June, 2018 - August, 2020 <br>
            </p>
            <p></p>
            <p>
              Deep learning and 3D computer vision research.
            </p>
          </td>
        </tr>

        <tr>
          <td width="25%"><img src="assets/nvidia_logo.png" alt="prl" width="150" ></td>
          <td width="75%" valign="top">
            <p>
              <big> Nvidia </big><br> 
              Research Intern<br>
              Toronto, Canada <br>
              May, 2017 - August, 2017 <br>
            </p>
            <p></p>
            <p>
               Deep learning research in animation and robotic perception.<br>
            </p>
          </td>
        </tr>

      </table>

     
      
      
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
          <td>
          <br>
          <p align="right">
            <font size="2">
            Template: <a href="https://github.com/jonbarron/jonbarron_website"><strong>This Guy</strong></a>
            </font>
          </p>
          </td>
      </tr>
      </table>


      
    </td>
    </tr>
  </table>

<script>
function detail_switch(click_id) {
    click_intro = click_id + '_content'
    var x = document.getElementById(click_intro);
    if (x.style.display === "none") {
        x.style.display = "block";
    } else {
        x.style.display = "none";
    }
}
</script>

  </body>
</html>
