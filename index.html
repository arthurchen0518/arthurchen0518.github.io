<!--  -->
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name="google-site-verification" content="3l9iSXOYZI5WUxYehDjXug3JAWy4ebqEpCvd3iuALWE" />
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="seal_icon.png">
  <title>Kefan (Arthur) Chen</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="67%" valign="middle">
          <p align="center">
            <name>Arthur (Kefan) Chen</name>
          </p>
            <p align="center">kefan_chen@brown.edu</p>
          <p>
            I'm a 3rd year Ph.D. candidate at Brown University, advised by <a href="https://cs.brown.edu/people/ssrinath/"> Prof. Srinath Sridhar</a>. 
            My research focuses on developing intelligent agents that understand and learn dexterous skills from humans, with the goal of enabling robotic assistance for everyday tasks.
            My expertise spans Generative AI, Large Vision Models (LVM), digital humans, neural rendering, and embodied AI. 
            Along my academic journey, I've done internships at Meta Reality Labs, Waymo Research, and NVIDIA. 
            <br><br>
            Prior to my PhD, I worked as a research scientist and ML engineer at Google Research, Pinterest, and various startups. I had the honor to work with <a href="http://www.ameeshmakadia.com/index.html"> Dr. Ameesh Makadia </a> and 
            <a href="https://www.cs.cornell.edu/~snavely/"> Prof. Noah Snavely</a> at Google Research; <a href="https://www.cs.toronto.edu/~urtasun/"> Prof. Raquel Urtasun</a> 
            and <a href="https://www.cs.utoronto.ca/~fidler/index.html"> Prof. Sanja Fidler</a> at UofT.
          </p>
          
          </td>
                                                                                                             
          <td width="33%">
            <img src="assets/portrait.jpg" width="200">
          </td>



        </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <p align=center>
          <img style="width: 18px; height:18px;" src="assets/resume_logo.png">
          <a href="assets/CurriculumVitae.pdf">CV</a> &nbsp / &nbsp
          <img style="width: 18px; height:18px;" src="assets/linkedIn_logo.png">
          <a href="https://www.linkedin.com/in/kefanc"> LinkedIn </a> &nbsp / &nbsp
          <img style="width: 18px; height:18px;" src="assets/google_scholar.jpg">
          <a href="https://scholar.google.com/citations?user=A6FPlHcAAAAJ&hl=en">Google Scholar</a>
        </p>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading>Publications</heading>
          </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        
        <tr bgcolor="#ffffff">
          <td width="25%">
            <img src="assets/foundhand.png" width='250'></div>   
          </td>
          <td valign="top" width="75%">
            <p>
              <papertitle>FoundHand: Large-Scale Domain-Specific Learning for Controllable Hand Image Generation</papertitle>
              <br><strong>K Chen</strong>*, C Min*, L Zhang, S Hampali, C Keskin, S Sridhar<br>
              <em>Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2025 <br>
              [<a href='https://arxiv.org/pdf/2412.02690'>Paper</a>]
<!--               [<a href='https://youtu.be/26tBmSOXxHo'>Video</a>] -->
              [<a href='https://ivl.cs.brown.edu/research/foundhand.html'>Website</a>]
             
              <br>
            </p>
          </td>
        </tr>
        
        <tr bgcolor="#ffffff">
          <td width="25%">
            <img src="assets/uvgs.jpg" width='250'></div>   
          </td>
          <td valign="top" width="75%">
            <p>
              <papertitle>UVGS: Reimagining Unstructured 3D Gaussian Splatting using UV Mapping</papertitle>
              <br>A Rai, D Wang, M Jain, N Sarafianos, <strong>K Chen</strong>, S Sridhar, A Prakash<br>
              <em>Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2025 <br>
              [<a href='https://www.arxiv.org/pdf/2502.01846'>Paper</a>]
              [<a href='https://youtu.be/Z-VcmzXbfzg'>Video</a>]
              [<a href='https://aashishrai3799.github.io/uvgs/'>Website</a>]
             
              <br>
            </p>
          </td>
        </tr>

        
        <tr bgcolor="#ffffff">
          <td width="25%">
            <img src="assets/MANUS.png" width='250'></div>   
          </td>
          <td valign="top" width="75%">
            <p>
              <papertitle>MANUS: Markerless Hand-Object Grasp Capture using Articulated 3D Gaussians</papertitle>
              <br>C Pokhariya, I Shah, A Xing, Z Li, <strong>K Chen</strong>, A Sharma, S Sridhar<br>
              <em>Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2024 <br>
              [<a href='https://arxiv.org/pdf/2312.02137.pdf'>Paper</a>]
              [<a href='https://ivl.cs.brown.edu/research/manus.html'>Website</a>]
              [<a href='https://github.com/brown-ivl/manus'>Code</a>]
              [<a href='https://github.com/brown-ivl/manus#manus-grasps-dataset'>Dataset</a>]
             
              <br>
            </p>
          </td>
        </tr>
        
        <tr bgcolor="#ffffff">
          <td width="25%">
            <img src="assets/diva360.png" width='250'></div>   
          </td>
          <td valign="top" width="75%">
            <p>
              <papertitle>DiVa-360: The Dynamic Visual Dataset for Immersive Neural Fields</papertitle>
              <br>C Lu, P Zhou, A Xing,  C Pokhariya, A Dey, I Shah, R Mavidipalli, D Hu, A Comport, <strong>K Chen</strong>, S Sridhar<br>
              <em>Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2024 <strong>(Highlight)</strong> <br>
              [<a href='https://arxiv.org/pdf/2307.16897.pdf'>Paper</a>]
              [<a href='https://youtu.be/26tBmSOXxHo'>Video</a>]
              [<a href='https://diva360.github.io/'>Website</a>]
              [<a href='https://github.com/brown-ivl/DiVa360'>Code</a>]
              [<a href='https://ivl.cs.brown.edu/research/diva#downloading-data'>Dataset</a>]
             
              
              
              
              <br>
            </p>
          </td>
        </tr>

        
        <tr bgcolor="#ffffff">
          <td width="25%">
            <img src="assets/TrainingPipeline_fill.png" width='250'></div>   
          </td>
          <td valign="top" width="75%">
            <p>
              <papertitle>Wide-Baseline Relative Camera Pose Estimation with Directional Learning</papertitle>
              <br>
              <strong>Kefan Chen</strong>, Noah, Snavely, Ameesh Makadia<br>
              <em>Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2021 <br>
              [<a href='https://arxiv.org/pdf/2106.03336.pdf'>Paper</a>]
              [<a id='directionnet_bib' onclick='detail_switch(this.id)'>Bibtex</a>]
              [<a href='https://www.youtube.com/watch?v=tJ2JTFmi0oI'>Video</a>]
              [<a href='https://arthurchen0518.github.io/DirectionNet'>Website</a>]
              [<a href='https://github.com/arthurchen0518/DirectionNet'>Code</a>]
              
              
              
              <br>
            </p>
            
            <p>
              <div id='directionnet_bib_content' style="font-family:monospace;display:none;">
@InProceedings{Chen_2021_CVPR,
    author    = {Chen, Kefan and Snavely, Noah and Makadia, Ameesh},
    title     = {Wide-Baseline Relative Camera Pose Estimation With Directional Learning},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {3258-3268}
}
                
              </div>
            </p>
            <p></p>
          </td>
        </tr>
  
        <tr bgcolor="#ffffff">
          <td width="25%"> 
            <img src="assets/svd_analysis.png" width='250'></div>  
          </td>
          <td valign="top" width="75%">
            <p>
              <papertitle>An Analysis of SVD for Deep Rotation Estimation</papertitle>
              <br>
              Jake Levinson, Carlos Esteves, <strong>Kefan Chen</strong>, Noah Snavely, Angjoo Kanazawa, Afshin Rostamizadeh, Ameesh Makadia<br>
              <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2020 <br>
              [<a href='https://arxiv.org/pdf/2006.14616.pdf'>Paper</a>]  
              [<a id='svd_bib' onclick='detail_switch(this.id)'>Bibtex</a>]  
              [<a href='https://www.youtube.com/watch?v=_lvz3KdZr_I'>Video</a>]
              [<a href='https://github.com/google-research/google-research/tree/master/special_orthogonalization'>Code</a>]
              
              <br>
            </p>

            <p>
              <div id='svd_bib_content' style="font-family:monospace;display:none;">
                @inproceedings{levinson20neurips,
                  title = {An Analysis of {SVD} for Deep Rotation Estimation},
                  author = {Jake Levinson, Carlos Esteves, Kefan Chen, Noah Snavely, Angjoo Kanazawa, Afshin Rostamizadeh, and Ameesh Makadia},
                  booktitle = {Advances in Neural Information Processing Systems 34},
                  year = {2020}
                }
              </div>
            </p>
            <p></p>

          </td>
        </tr>

      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td>
          <heading>Education</heading>
          </td>
        </tr>
        
      </table>
      
      <table width="100%" align="center" border="0" cellpadding="20">
        <tr>
          <td width="25%"><img src="assets/brown.png" alt="prl" width="160" ></td>
          <td width="75%" valign="top">
            <p>
              <big>Brown University</big> <br> 
              Ph.D. student in Computer Science <br>
              Research Areas:	GenAI, large vision models, digital human, 3D computer vision. <br>
              2022 - 2027 <br>
            </p>
          </td>
        </tr>
        
        <tr>
          <td width="25%"><img src="assets/UofT-Logo.png" alt="prl" width="160" ></td>
          <td width="75%" valign="top">
            <p>
              <big>University of Toronto</big> <br> 
              B.Eng. in Electrical Engineering <br>
              2014 - 2018 <br>
            </p>
          </td>
        </tr>
        
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td>
          <heading>Industry</heading>
          </td>
        </tr>
        
      </table>
       
        
      <table width="100%" align="center" border="0" cellpadding="20">
        
        <tr>
          <td width="25%"><img src="assets/Waymo_logo.png" alt="prl" width="145" ></td>
          <td width="75%" valign="top">
            <p>
              <big>Waymo</big> <br> 
              Research Intern<br>
              Mountainview, CA <br>
              June, 2025 -  Current<br>
            </p>
            <p></p>
            <p>
              Research perception on L4 autonomous driving.
            </p>
          </td>
        </tr>
        
        <tr>
          <td width="25%"><img src="assets/meta-logo.png" alt="prl" width="160" ></td>
          <td width="75%" valign="top">
            <p>
              <big>Meta</big> <br> 
              Research Scientist Intern<br>
              Seattle, WA; Burlingame, CA <br>
              June, 2023 - Dec, 2023; June, 2024 - Mar, 2025  <br>
            </p>
            <p></p>
            <p>
              Research large image and video diffusion model for dexterous hand generation.
            </p>
            <p>
              Research interactive 3D human avatars using Gaussian Splatting for realistic digital human and VR/XR.
            </p>
            
          </td>
        </tr>

        <tr>
          <td width="25%"><img src="assets/Pinterest-Logo.png" alt="prl" width="160" ></td>
          <td width="75%" valign="top">
            <p>
              <big>Pinterest</big> <br> 
              Machine Learning Engineer<br>
              Toronto, Canada <br>
              January, 2022 -  September, 2022<br>
            </p>
            <p></p>
            <p>
              ML for shopping content mining.
            </p>
          </td>
        </tr>
<!--         
        <tr>
          <td width="25%"><img src="assets/gatik_logo.png" alt="prl" width="160" ></td>
          <td width="75%" valign="top">
            <p>
              <big>Gatik</big> <br> 
              Toronto, Canada <br>
              September, 2020 - December, 2021 <br>
            </p>
            <p></p>
            <p>
              Develop long-range multimodal perception for self-driving trucks.
            </p>
          </td>
        </tr> -->
        
        <tr>
          <td width="25%"><img src="assets/google_research_logo.jpg" alt="prl" width="180" ></td>
          <td width="75%" valign="top">
            <p>
              <big>Google Research</big> <br> 
              AI Resident<br>
              New York City, NY <br>
              June, 2018 - August, 2020 <br>
            </p>
            <p></p>
            <p>
              Deep learning and 3D computer vision research.
            </p>
          </td>
        </tr>

        <tr>
          <td width="25%"><img src="assets/nvidia_logo.png" alt="prl" width="150" ></td>
          <td width="75%" valign="top">
            <p>
              <big>Nvidia Corporation </big><br> 
              Research Intern<br>
              Toronto, Canada <br>
              May, 2017 - August, 2017 <br>
            </p>
            <p></p>
            <p>
               Deep learning research in animation and robotic perception.<br>
            </p>
          </td>
        </tr>

      </table>

     
      
      
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
          <td>
          <br>
          <p align="right">
            <font size="2">
            Template: <a href="https://github.com/jonbarron/jonbarron_website"><strong>This Guy</strong></a>
            </font>
          </p>
          </td>
      </tr>
      </table>


      
    </td>
    </tr>
  </table>

<script>
function detail_switch(click_id) {
    click_intro = click_id + '_content'
    var x = document.getElementById(click_intro);
    if (x.style.display === "none") {
        x.style.display = "block";
    } else {
        x.style.display = "none";
    }
}
</script>

  </body>
</html>
